{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collecting Data with User Name Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Prompt user for their name\n",
    "user_name = input(\"Please enter your name: \").strip()\n",
    "\n",
    "# Main directory to save the collected images\n",
    "main_data_dir = 'Dataset'\n",
    "\n",
    "# Subdirectory for the user\n",
    "user_dir = os.path.join(main_data_dir, user_name)\n",
    "\n",
    "if not os.path.exists(user_dir):\n",
    "    os.makedirs(user_dir)\n",
    "    print(f\"Directory created for {user_name}. Proceeding to collect data...\")\n",
    "else:\n",
    "    print(f\"Directory for {user_name} already exists. Proceeding to collect data...\")\n",
    "\n",
    "# Initialize the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "count = 0\n",
    "while count < 100:  # Capture 100 images\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        face = gray[y:y+h, x:x+w]\n",
    "        cv2.imwrite(os.path.join(user_dir, f'{user_name}_{count}.jpg'), face)\n",
    "        count += 1\n",
    "        time.sleep(0.2)  # Add a 0.5 seconds delay\n",
    "    \n",
    "    cv2.imshow('Collecting Your Face Data', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "# Load your dataset\n",
    "def load_data(data_dir):\n",
    "    images = []\n",
    "    labels = []\n",
    "    label_dict = {}\n",
    "    current_label = 0\n",
    "    \n",
    "    for person_name in os.listdir(data_dir):\n",
    "        person_dir = os.path.join(data_dir, person_name)\n",
    "        if not os.path.isdir(person_dir):\n",
    "            continue\n",
    "        \n",
    "        for image_name in os.listdir(person_dir):\n",
    "            image_path = os.path.join(person_dir, image_name)\n",
    "            image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "            image = cv2.resize(image, (128, 128))\n",
    "            images.append(image)\n",
    "            if person_name not in label_dict:\n",
    "                label_dict[person_name] = current_label\n",
    "                current_label += 1\n",
    "            labels.append(label_dict[person_name])\n",
    "    \n",
    "    images = np.array(images).reshape(-1, 128, 128, 1)\n",
    "    labels = np.array(labels)\n",
    "    return images, labels, label_dict\n",
    "\n",
    "data_dir = 'Dataset'\n",
    "images, labels, label_dict = load_data(data_dir)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build the model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 1)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(len(label_dict), activation='softmax'))  # Use softmax for multi-class classification\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Save the model and label dictionary\n",
    "model.save('face_recognition_model.h5')\n",
    "np.save('label_dict.npy', label_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Real-time Face Detection and Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the pre-trained model and label dictionary\n",
    "model = load_model('face_recognition_model.h5')\n",
    "label_dict = np.load('label_dict.npy', allow_pickle=True).item()\n",
    "\n",
    "def preprocess_image(image):\n",
    "    image = cv2.resize(image, (128, 128))\n",
    "    image = image.reshape(1, 128, 128, 1)\n",
    "    image = image / 255.0\n",
    "    return image\n",
    "\n",
    "def predict_face(image, model, label_dict):\n",
    "    processed_image = preprocess_image(image)\n",
    "    prediction = model.predict(processed_image)\n",
    "    label = np.argmax(prediction)\n",
    "    confidence = np.max(prediction)\n",
    "    if confidence > 0.5:  # Confidence threshold\n",
    "        return list(label_dict.keys())[list(label_dict.values()).index(label)], confidence\n",
    "    else:\n",
    "        return \"Unknown\", confidence\n",
    "\n",
    "# Initialize the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        face = gray[y:y+h, x:x+w]\n",
    "        label, confidence = predict_face(face, model, label_dict)\n",
    "        \n",
    "        if label != \"Unknown\":\n",
    "            color = (0, 255, 0)\n",
    "        else:\n",
    "            color = (0, 0, 255)\n",
    "        \n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), color, 2)\n",
    "        cv2.putText(frame, f'{label} ({confidence*100:.2f}%)', (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)\n",
    "\n",
    "    cv2.imshow('Face Recognition', frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
